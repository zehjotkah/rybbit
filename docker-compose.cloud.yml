# DON'T USE THIS FILE, USE docker-compose.yml instead

services:
  caddy:
    image: caddy:2.10.0
    container_name: caddy
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
      - "443:443/udp" # Needed for HTTP/3
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile # Mount Caddy config file
      - caddy_data:/data # Mount persistent data volume for certs etc.
      - caddy_config:/config # Mount persistent config volume
    environment:
      # Pass domain name for use in Caddyfile
      # Email is configured via Caddyfile global options
      - DOMAIN_NAME=${DOMAIN_NAME}
    depends_on:
      - backend
      - client

  clickhouse:
    container_name: clickhouse
    image: clickhouse/clickhouse-server:25.4.2
    volumes:
      - clickhouse-data:/var/lib/clickhouse
    configs:
      - source: clickhouse_network
        target: /etc/clickhouse-server/config.d/network.xml
      - source: clickhouse_json
        target: /etc/clickhouse-server/config.d/enable_json.xml
      - source: clickhouse_logging
        target: /etc/clickhouse-server/config.d/logging_rules.xml
      - source: clickhouse_user_logging
        target: /etc/clickhouse-server/config.d/user_logging.xml
    environment:
      - CLICKHOUSE_DB=${CLICKHOUSE_DB:-analytics}
      - CLICKHOUSE_USER=${CLICKHOUSE_USER:-default}
      - CLICKHOUSE_PASSWORD=${CLICKHOUSE_PASSWORD:-frog}
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8123/ping"]
      interval: 3s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped
    ports:
      - "8123:8123"
      - "9000:9000"
    mem_limit: 12g
    mem_reservation: 6g
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  postgres:
    image: postgres:17.4
    container_name: postgres
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-frog}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-frog}
      - POSTGRES_DB=${POSTGRES_DB:-analytics}
    volumes:
      - postgres-data:/var/lib/postgresql/data
    restart: unless-stopped
    ports:
      - "5432:5432"

  redis:
    image: redis:7-alpine
    container_name: redis
    ports:
      - "6379:6379" # Exposed to internet for remote connections
    volumes:
      - redis-data:/data
    restart: unless-stopped
    command: ["redis-server", "--requirepass", "${REDIS_PASSWORD:-changeme}", "--appendonly", "yes"]

  backend:
    container_name: backend
    build:
      context: .
      dockerfile: ./server/Dockerfile
    environment:
      - NODE_ENV=production
      - CLICKHOUSE_HOST=http://clickhouse:8123
      - CLICKHOUSE_DB=${CLICKHOUSE_DB:-analytics}
      - CLICKHOUSE_PASSWORD=${CLICKHOUSE_PASSWORD:-frog}
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=${POSTGRES_DB:-analytics}
      - POSTGRES_USER=${POSTGRES_USER:-frog}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-frog}
      - BETTER_AUTH_SECRET=${BETTER_AUTH_SECRET}
      - BASE_URL=${BASE_URL}
      - DISABLE_SIGNUP=${DISABLE_SIGNUP}
      # below is only for rybbit cloud
      - CLOUD=${CLOUD}
      - STRIPE_SECRET_KEY=${STRIPE_SECRET_KEY}
      - STRIPE_WEBHOOK_SECRET=${STRIPE_WEBHOOK_SECRET}
      # AppSumo configuration
      - APPSUMO_CLIENT_ID=${APPSUMO_CLIENT_ID}
      - APPSUMO_CLIENT_SECRET=${APPSUMO_CLIENT_SECRET}
      - GOOGLE_CLIENT_ID=${GOOGLE_CLIENT_ID}
      - GOOGLE_CLIENT_SECRET=${GOOGLE_CLIENT_SECRET}
      - GITHUB_CLIENT_ID=${GITHUB_CLIENT_ID}
      - GITHUB_CLIENT_SECRET=${GITHUB_CLIENT_SECRET}
      - RESEND_API_KEY=${RESEND_API_KEY}
      # Twilio SMS configuration (cloud only)
      - TWILIO_ACCOUNT_SID=${TWILIO_ACCOUNT_SID}
      - TWILIO_AUTH_TOKEN=${TWILIO_AUTH_TOKEN}
      - TWILIO_PHONE_NUMBER=${TWILIO_PHONE_NUMBER}
      # R2 storage for session replay (cloud only)
      - R2_ACCOUNT_ID=${R2_ACCOUNT_ID}
      - R2_ACCESS_KEY_ID=${R2_ACCESS_KEY_ID}
      - R2_SECRET_ACCESS_KEY=${R2_SECRET_ACCESS_KEY}
      - R2_BUCKET_NAME=${R2_BUCKET_NAME:-rybbit}
      # Redis configuration
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=${REDIS_PASSWORD:-changeme}
      # Axiom logging configuration (optional)
      - AXIOM_DATASET=${AXIOM_DATASET}
      - AXIOM_TOKEN=${AXIOM_TOKEN}
      - MAPBOX_TOKEN=${MAPBOX_TOKEN}
      - TURNSTILE_SECRET_KEY=${TURNSTILE_SECRET_KEY}
      - IPAPI_KEY=${IPAPI_KEY}
    depends_on:
      clickhouse:
        condition: service_healthy
      postgres:
        condition: service_started
      redis:
        condition: service_started
    restart: unless-stopped
    ports:
      - "3001:3001"

  client:
    container_name: client
    build:
      context: .
      dockerfile: ./client/Dockerfile
      args:
        NEXT_PUBLIC_BACKEND_URL: ${BASE_URL}
        NEXT_PUBLIC_DISABLE_SIGNUP: ${DISABLE_SIGNUP}
        NEXT_PUBLIC_CLOUD: ${CLOUD}
        NEXT_PUBLIC_MAPBOX_TOKEN: ${MAPBOX_TOKEN}
        NEXT_PUBLIC_TURNSTILE_SITE_KEY: ${TURNSTILE_SITE_KEY}
    environment:
      - NODE_ENV=production
      - NEXT_PUBLIC_BACKEND_URL=${BASE_URL}
      - NEXT_PUBLIC_DISABLE_SIGNUP=${DISABLE_SIGNUP}
      - NEXT_PUBLIC_CLOUD=${CLOUD}
      - NEXT_PUBLIC_MAPBOX_TOKEN=${MAPBOX_TOKEN}
      - NEXT_PUBLIC_TURNSTILE_SITE_KEY=${TURNSTILE_SITE_KEY}
    depends_on:
      - backend
    restart: unless-stopped
    ports:
      - "3002:3002"

volumes:
  clickhouse-data:
  postgres-data:
  redis-data:
  caddy_data: # Persistent volume for Caddy's certificates and state
  caddy_config: # Persistent volume for Caddy's configuration cache (optional but good practice)

configs:
  clickhouse_network:
    content: |
      <clickhouse>
          <listen_host>0.0.0.0</listen_host>
      </clickhouse>

  clickhouse_json:
    content: |
      <clickhouse>
          <settings>
              <enable_json_type>1</enable_json_type>
              <max_concurrent_queries>20</max_concurrent_queries>
              <background_pool_size>4</background_pool_size>
              <background_merges_mutations_concurrency_ratio>1</background_merges_mutations_concurrency_ratio>
              <mark_cache_size>524288000</mark_cache_size>
          </settings>
      </clickhouse>

  clickhouse_logging:
    content: |
      <clickhouse>
        <logger>
            <level>warning</level>
            <console>true</console>
        </logger>
        <query_thread_log remove="remove"/>
        <query_log remove="remove"/>
        <text_log remove="remove"/>
        <trace_log remove="remove"/>
        <metric_log remove="remove"/>
        <asynchronous_metric_log remove="remove"/>
        <session_log remove="remove"/>
        <part_log remove="remove"/>
        <latency_log remove="remove"/>
        <processors_profile_log remove="remove"/>
      </clickhouse>

  clickhouse_user_logging:
    content: |
      <clickhouse>
        <profiles>
          <default>
            <log_queries>0</log_queries>
            <log_query_threads>0</log_query_threads>
            <log_processors_profiles>0</log_processors_profiles>
            <max_memory_usage>8000000000</max_memory_usage>
            <max_bytes_before_external_group_by>4000000000</max_bytes_before_external_group_by>
            <max_bytes_before_external_sort>4000000000</max_bytes_before_external_sort>
            <max_threads>4</max_threads>
            <max_block_size>8192</max_block_size>
            <input_format_parallel_parsing>0</input_format_parallel_parsing>
          </default>
        </profiles>
      </clickhouse>
